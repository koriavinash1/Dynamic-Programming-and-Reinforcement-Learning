{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole: REINFORCE Monte Carlo Policy Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll implement an agent <b>that plays Cartpole </b>\n",
    "\n",
    "<img src=\"http://neuro-educator.com/wp-content/uploads/2017/09/DQN.gif\" alt=\"Cartpole gif\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is part of the Free Deep Reinforcement Course üìù\n",
    "<img src=\"https://simoninithomas.github.io/Deep_reinforcement_learning_Course/assets/img/preview.jpg\" alt=\"Deep Reinforcement Course\" style=\"width: 500px;\"/>\n",
    "\n",
    "<p> Deep Reinforcement Learning Course is a free series of blog posts about Deep Reinforcement Learning, where we'll learn the main algorithms, <b>and how to implement them in Tensorflow.</b></p>\n",
    "\n",
    "<p>The goal of these articles is to <b>explain step by step from the big picture</b> and the mathematical details behind it, to the implementation with Tensorflow </p>\n",
    "\n",
    "\n",
    "<a href=\"https://simoninithomas.github.io/Deep_reinforcement_learning_Course/\">Syllabus</a><br>\n",
    "<a href=\"https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419\">Part 0: Introduction to Reinforcement Learning </a><br>\n",
    "<a href=\"https://medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe\"> Part 1: Q-learning with FrozenLake</a><br>\n",
    "<a href=\"https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8\"> Part 2: Deep Q-learning with Doom</a><br>\n",
    "<a href=\"\"> Part 3: Policy Gradients with Doom </a><br>\n",
    "\n",
    "## Checklist üìù\n",
    "- To launch tensorboard : `tensorboard --logdir=/tensorboard/pg/1`\n",
    "- ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è You need to download vizdoom and place the folder in the repos.\n",
    "- If don't want to train, you must change **training to False** (in hyperparameters step). \n",
    "\n",
    "\n",
    "## Any questions üë®‚Äçüíª\n",
    "<p> If you have any questions, feel free to ask me: </p>\n",
    "<p> üìß: <a href=\"mailto:hello@simoninithomas.com\">hello@simoninithomas.com</a>  </p>\n",
    "<p> Github: https://github.com/simoninithomas/Deep_reinforcement_learning_Course </p>\n",
    "<p> üåê : https://simoninithomas.github.io/Deep_reinforcement_learning_Course/ </p>\n",
    "<p> Twitter: <a href=\"https://twitter.com/ThomasSimonini\">@ThomasSimonini</a> </p>\n",
    "<p> Don't forget to <b> follow me on <a href=\"https://twitter.com/ThomasSimonini\">twitter</a>, <a href=\"https://github.com/simoninithomas/Deep_reinforcement_learning_Course\">github</a> and <a href=\"https://medium.com/@thomassimonini\">Medium</a> to be alerted of the new articles that I publish </b></p>\n",
    "    \n",
    "\n",
    "## How to help  üôå\n",
    "3 ways:\n",
    "- **Clap our articles a lot**:Clapping in Medium means that you really like our articles. And the more claps we have, the more our article is shared\n",
    "- **Share and speak about our articles**: By sharing our articles you help us to spread the word.\n",
    "- **Improve our notebooks**: if you found a bug or **a better implementation** you can send a pull request.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create our environment üéÆ\n",
    "This time we use <a href=\"https://gym.openai.com/\">OpenAI Gym</a> which has a lot of great environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env = env.unwrapped\n",
    "# Policy gradient has high variance, seed for reproducability\n",
    "env.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set up our hyperparameters ‚öóÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENVIRONMENT Hyperparameters\n",
    "state_size = 4\n",
    "action_size = env.action_space.n\n",
    "\n",
    "## TRAINING Hyperparameters\n",
    "max_episodes = 10000\n",
    "learning_rate = 0.01\n",
    "gamma = 0.95 # Discount rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Define the preprocessing functions ‚öôÔ∏è\n",
    "This function takes <b>the rewards and perform discounting.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_and_normalize_rewards(episode_rewards):\n",
    "    discounted_episode_rewards = np.zeros_like(episode_rewards)\n",
    "    cumulative = 0.0\n",
    "    for i in reversed(range(len(episode_rewards))):\n",
    "        cumulative = cumulative * gamma + episode_rewards[i]\n",
    "        discounted_episode_rewards[i] = cumulative\n",
    "    \n",
    "    mean = np.mean(discounted_episode_rewards)\n",
    "    std = np.std(discounted_episode_rewards)\n",
    "    discounted_episode_rewards = (discounted_episode_rewards - mean) / (std)\n",
    "    \n",
    "    return discounted_episode_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create our Policy Gradient Neural Network model üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/master/Policy%20Gradients/Cartpole/assets/catpole.png\">\n",
    "\n",
    "The idea is simple:\n",
    "- Our state which is an array of 4 values will be used as an input.\n",
    "- Our NN is 3 fully connected layers.\n",
    "- Our output activation function is softmax that squashes the outputs to a probability distribution (for instance if we have 4, 2, 6 --> softmax --> (0.4, 0.2, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"inputs\"):\n",
    "    input_ = tf.placeholder(tf.float32, [None, state_size], name=\"input_\")\n",
    "    actions = tf.placeholder(tf.int32, [None, action_size], name=\"actions\")\n",
    "    discounted_episode_rewards_ = tf.placeholder(tf.float32, [None,], name=\"discounted_episode_rewards\")\n",
    "    \n",
    "    # Add this placeholder for having this variable in tensorboard\n",
    "    mean_reward_ = tf.placeholder(tf.float32 , name=\"mean_reward\")\n",
    "\n",
    "    with tf.name_scope(\"fc1\"):\n",
    "        fc1 = tf.contrib.layers.fully_connected(inputs = input_,\n",
    "                                                num_outputs = 10,\n",
    "                                                activation_fn=tf.nn.relu,\n",
    "                                                weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    with tf.name_scope(\"fc2\"):\n",
    "        fc2 = tf.contrib.layers.fully_connected(inputs = fc1,\n",
    "                                                num_outputs = action_size,\n",
    "                                                activation_fn= tf.nn.relu,\n",
    "                                                weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    with tf.name_scope(\"fc3\"):\n",
    "        fc3 = tf.contrib.layers.fully_connected(inputs = fc2,\n",
    "                                                num_outputs = action_size,\n",
    "                                                activation_fn= None,\n",
    "                                                weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        action_distribution = tf.nn.softmax(fc3)\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        # tf.nn.softmax_cross_entropy_with_logits computes the cross entropy of the result after applying the softmax function\n",
    "        # If you have single-class labels, where an object can only belong to one class, you might now consider using \n",
    "        # tf.nn.sparse_softmax_cross_entropy_with_logits so that you don't have to convert your labels to a dense one-hot array. \n",
    "        neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits = fc3, labels = actions)\n",
    "        loss = tf.reduce_mean(neg_log_prob * discounted_episode_rewards_) \n",
    "        \n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Set up Tensorboard üìä\n",
    "For more information about tensorboard, please watch this <a href=\"https://www.youtube.com/embed/eBbEDRsCmv4\">excellent 30min tutorial</a> <br><br>\n",
    "To launch tensorboard : `tensorboard --logdir=/tensorboard/pg/1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorBoard Writer\n",
    "writer = tf.summary.FileWriter(\"/tensorboard/pg/1\")\n",
    "\n",
    "## Losses\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "\n",
    "## Reward mean\n",
    "tf.summary.scalar(\"Reward_mean\", mean_reward_)\n",
    "\n",
    "write_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train our Agent üèÉ‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create the NN\n",
    "maxReward = 0 # Keep track of maximum reward\n",
    "For episode in range(max_episodes):\n",
    "    episode + 1\n",
    "    reset environment\n",
    "    reset stores (states, actions, rewards)\n",
    "    \n",
    "    For each step:\n",
    "        Choose action a\n",
    "        Perform action a\n",
    "        Store s, a, r\n",
    "        If done:\n",
    "            Calculate sum reward\n",
    "            Calculate gamma Gt\n",
    "            Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  0\n",
      "Reward:  21.0\n",
      "Mean Reward 21.0\n",
      "Max reward so far:  21.0\n",
      "==========================================\n",
      "Episode:  1\n",
      "Reward:  10.0\n",
      "Mean Reward 15.5\n",
      "Max reward so far:  21.0\n",
      "==========================================\n",
      "Episode:  2\n",
      "Reward:  14.0\n",
      "Mean Reward 15.0\n",
      "Max reward so far:  21.0\n",
      "==========================================\n",
      "Episode:  3\n",
      "Reward:  13.0\n",
      "Mean Reward 14.5\n",
      "Max reward so far:  21.0\n",
      "==========================================\n",
      "Episode:  4\n",
      "Reward:  18.0\n",
      "Mean Reward 15.2\n",
      "Max reward so far:  21.0\n",
      "==========================================\n",
      "Episode:  5\n",
      "Reward:  22.0\n",
      "Mean Reward 16.3333333333\n",
      "Max reward so far:  22.0\n",
      "==========================================\n",
      "Episode:  6\n",
      "Reward:  27.0\n",
      "Mean Reward 17.8571428571\n",
      "Max reward so far:  27.0\n",
      "==========================================\n",
      "Episode:  7\n",
      "Reward:  21.0\n",
      "Mean Reward 18.25\n",
      "Max reward so far:  27.0\n",
      "==========================================\n",
      "Episode:  8\n",
      "Reward:  50.0\n",
      "Mean Reward 21.7777777778\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  9\n",
      "Reward:  17.0\n",
      "Mean Reward 21.3\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  10\n",
      "Reward:  23.0\n",
      "Mean Reward 21.4545454545\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  11\n",
      "Reward:  17.0\n",
      "Mean Reward 21.0833333333\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  12\n",
      "Reward:  21.0\n",
      "Mean Reward 21.0769230769\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  13\n",
      "Reward:  11.0\n",
      "Mean Reward 20.3571428571\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  14\n",
      "Reward:  23.0\n",
      "Mean Reward 20.5333333333\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  15\n",
      "Reward:  16.0\n",
      "Mean Reward 20.25\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  16\n",
      "Reward:  17.0\n",
      "Mean Reward 20.0588235294\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  17\n",
      "Reward:  16.0\n",
      "Mean Reward 19.8333333333\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  18\n",
      "Reward:  28.0\n",
      "Mean Reward 20.2631578947\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  19\n",
      "Reward:  27.0\n",
      "Mean Reward 20.6\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  20\n",
      "Reward:  11.0\n",
      "Mean Reward 20.1428571429\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  21\n",
      "Reward:  24.0\n",
      "Mean Reward 20.3181818182\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  22\n",
      "Reward:  29.0\n",
      "Mean Reward 20.6956521739\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  23\n",
      "Reward:  29.0\n",
      "Mean Reward 21.0416666667\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  24\n",
      "Reward:  17.0\n",
      "Mean Reward 20.88\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  25\n",
      "Reward:  22.0\n",
      "Mean Reward 20.9230769231\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  26\n",
      "Reward:  29.0\n",
      "Mean Reward 21.2222222222\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  27\n",
      "Reward:  12.0\n",
      "Mean Reward 20.8928571429\n",
      "Max reward so far:  50.0\n",
      "==========================================\n",
      "Episode:  28\n",
      "Reward:  69.0\n",
      "Mean Reward 22.5517241379\n",
      "Max reward so far:  69.0\n",
      "==========================================\n",
      "Episode:  29\n",
      "Reward:  71.0\n",
      "Mean Reward 24.1666666667\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  30\n",
      "Reward:  25.0\n",
      "Mean Reward 24.1935483871\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  31\n",
      "Reward:  11.0\n",
      "Mean Reward 23.78125\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  32\n",
      "Reward:  14.0\n",
      "Mean Reward 23.4848484848\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  33\n",
      "Reward:  25.0\n",
      "Mean Reward 23.5294117647\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  34\n",
      "Reward:  17.0\n",
      "Mean Reward 23.3428571429\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  35\n",
      "Reward:  15.0\n",
      "Mean Reward 23.1111111111\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  36\n",
      "Reward:  16.0\n",
      "Mean Reward 22.9189189189\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  37\n",
      "Reward:  22.0\n",
      "Mean Reward 22.8947368421\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  38\n",
      "Reward:  12.0\n",
      "Mean Reward 22.6153846154\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  39\n",
      "Reward:  22.0\n",
      "Mean Reward 22.6\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  40\n",
      "Reward:  36.0\n",
      "Mean Reward 22.9268292683\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  41\n",
      "Reward:  20.0\n",
      "Mean Reward 22.8571428571\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  42\n",
      "Reward:  14.0\n",
      "Mean Reward 22.6511627907\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  43\n",
      "Reward:  16.0\n",
      "Mean Reward 22.5\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  44\n",
      "Reward:  13.0\n",
      "Mean Reward 22.2888888889\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  45\n",
      "Reward:  31.0\n",
      "Mean Reward 22.4782608696\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  46\n",
      "Reward:  15.0\n",
      "Mean Reward 22.3191489362\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  47\n",
      "Reward:  34.0\n",
      "Mean Reward 22.5625\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  48\n",
      "Reward:  71.0\n",
      "Mean Reward 23.5510204082\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  49\n",
      "Reward:  22.0\n",
      "Mean Reward 23.52\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  50\n",
      "Reward:  12.0\n",
      "Mean Reward 23.2941176471\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  51\n",
      "Reward:  23.0\n",
      "Mean Reward 23.2884615385\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  52\n",
      "Reward:  31.0\n",
      "Mean Reward 23.4339622642\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  53\n",
      "Reward:  18.0\n",
      "Mean Reward 23.3333333333\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  54\n",
      "Reward:  33.0\n",
      "Mean Reward 23.5090909091\n",
      "Max reward so far:  71.0\n",
      "==========================================\n",
      "Episode:  55\n",
      "Reward:  87.0\n",
      "Mean Reward 24.6428571429\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  56\n",
      "Reward:  16.0\n",
      "Mean Reward 24.4912280702\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  57\n",
      "Reward:  33.0\n",
      "Mean Reward 24.6379310345\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  58\n",
      "Reward:  45.0\n",
      "Mean Reward 24.9830508475\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  59\n",
      "Reward:  24.0\n",
      "Mean Reward 24.9666666667\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  60\n",
      "Reward:  47.0\n",
      "Mean Reward 25.3278688525\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  61\n",
      "Reward:  11.0\n",
      "Mean Reward 25.0967741935\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  62\n",
      "Reward:  25.0\n",
      "Mean Reward 25.0952380952\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  63\n",
      "Reward:  14.0\n",
      "Mean Reward 24.921875\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  64\n",
      "Reward:  15.0\n",
      "Mean Reward 24.7692307692\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  65\n",
      "Reward:  13.0\n",
      "Mean Reward 24.5909090909\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  66\n",
      "Reward:  23.0\n",
      "Mean Reward 24.5671641791\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  67\n",
      "Reward:  27.0\n",
      "Mean Reward 24.6029411765\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  68\n",
      "Reward:  42.0\n",
      "Mean Reward 24.8550724638\n",
      "Max reward so far:  87.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  69\n",
      "Reward:  16.0\n",
      "Mean Reward 24.7285714286\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  70\n",
      "Reward:  20.0\n",
      "Mean Reward 24.661971831\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  71\n",
      "Reward:  58.0\n",
      "Mean Reward 25.125\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  72\n",
      "Reward:  22.0\n",
      "Mean Reward 25.0821917808\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  73\n",
      "Reward:  33.0\n",
      "Mean Reward 25.1891891892\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  74\n",
      "Reward:  37.0\n",
      "Mean Reward 25.3466666667\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  75\n",
      "Reward:  17.0\n",
      "Mean Reward 25.2368421053\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  76\n",
      "Reward:  15.0\n",
      "Mean Reward 25.1038961039\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  77\n",
      "Reward:  27.0\n",
      "Mean Reward 25.1282051282\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  78\n",
      "Reward:  53.0\n",
      "Mean Reward 25.4810126582\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  79\n",
      "Reward:  10.0\n",
      "Mean Reward 25.2875\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  80\n",
      "Reward:  24.0\n",
      "Mean Reward 25.2716049383\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  81\n",
      "Reward:  16.0\n",
      "Mean Reward 25.1585365854\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  82\n",
      "Reward:  38.0\n",
      "Mean Reward 25.313253012\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  83\n",
      "Reward:  21.0\n",
      "Mean Reward 25.2619047619\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  84\n",
      "Reward:  18.0\n",
      "Mean Reward 25.1764705882\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  85\n",
      "Reward:  22.0\n",
      "Mean Reward 25.1395348837\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  86\n",
      "Reward:  20.0\n",
      "Mean Reward 25.0804597701\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  87\n",
      "Reward:  17.0\n",
      "Mean Reward 24.9886363636\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  88\n",
      "Reward:  18.0\n",
      "Mean Reward 24.9101123596\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  89\n",
      "Reward:  16.0\n",
      "Mean Reward 24.8111111111\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  90\n",
      "Reward:  21.0\n",
      "Mean Reward 24.7692307692\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  91\n",
      "Reward:  38.0\n",
      "Mean Reward 24.9130434783\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  92\n",
      "Reward:  16.0\n",
      "Mean Reward 24.8172043011\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  93\n",
      "Reward:  19.0\n",
      "Mean Reward 24.7553191489\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  94\n",
      "Reward:  18.0\n",
      "Mean Reward 24.6842105263\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  95\n",
      "Reward:  15.0\n",
      "Mean Reward 24.5833333333\n",
      "Max reward so far:  87.0\n",
      "==========================================\n",
      "Episode:  96\n",
      "Reward:  109.0\n",
      "Mean Reward 25.4536082474\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  97\n",
      "Reward:  42.0\n",
      "Mean Reward 25.6224489796\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  98\n",
      "Reward:  21.0\n",
      "Mean Reward 25.5757575758\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  99\n",
      "Reward:  22.0\n",
      "Mean Reward 25.54\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  100\n",
      "Reward:  13.0\n",
      "Mean Reward 25.4158415842\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  101\n",
      "Reward:  18.0\n",
      "Mean Reward 25.3431372549\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  102\n",
      "Reward:  13.0\n",
      "Mean Reward 25.2233009709\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  103\n",
      "Reward:  23.0\n",
      "Mean Reward 25.2019230769\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  104\n",
      "Reward:  32.0\n",
      "Mean Reward 25.2666666667\n",
      "Max reward so far:  109.0\n",
      "==========================================\n",
      "Episode:  105\n",
      "Reward:  136.0\n",
      "Mean Reward 26.3113207547\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  106\n",
      "Reward:  40.0\n",
      "Mean Reward 26.4392523364\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  107\n",
      "Reward:  22.0\n",
      "Mean Reward 26.3981481481\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  108\n",
      "Reward:  40.0\n",
      "Mean Reward 26.5229357798\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  109\n",
      "Reward:  57.0\n",
      "Mean Reward 26.8\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  110\n",
      "Reward:  12.0\n",
      "Mean Reward 26.6666666667\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  111\n",
      "Reward:  34.0\n",
      "Mean Reward 26.7321428571\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  112\n",
      "Reward:  18.0\n",
      "Mean Reward 26.6548672566\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  113\n",
      "Reward:  43.0\n",
      "Mean Reward 26.798245614\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  114\n",
      "Reward:  63.0\n",
      "Mean Reward 27.1130434783\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  115\n",
      "Reward:  46.0\n",
      "Mean Reward 27.275862069\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  116\n",
      "Reward:  50.0\n",
      "Mean Reward 27.4700854701\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  117\n",
      "Reward:  14.0\n",
      "Mean Reward 27.3559322034\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  118\n",
      "Reward:  87.0\n",
      "Mean Reward 27.8571428571\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  119\n",
      "Reward:  25.0\n",
      "Mean Reward 27.8333333333\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  120\n",
      "Reward:  23.0\n",
      "Mean Reward 27.7933884298\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  121\n",
      "Reward:  74.0\n",
      "Mean Reward 28.1721311475\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  122\n",
      "Reward:  61.0\n",
      "Mean Reward 28.4390243902\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  123\n",
      "Reward:  80.0\n",
      "Mean Reward 28.8548387097\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  124\n",
      "Reward:  38.0\n",
      "Mean Reward 28.928\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  125\n",
      "Reward:  101.0\n",
      "Mean Reward 29.5\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  126\n",
      "Reward:  26.0\n",
      "Mean Reward 29.4724409449\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  127\n",
      "Reward:  31.0\n",
      "Mean Reward 29.484375\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  128\n",
      "Reward:  42.0\n",
      "Mean Reward 29.5813953488\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  129\n",
      "Reward:  23.0\n",
      "Mean Reward 29.5307692308\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  130\n",
      "Reward:  62.0\n",
      "Mean Reward 29.7786259542\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  131\n",
      "Reward:  58.0\n",
      "Mean Reward 29.9924242424\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  132\n",
      "Reward:  33.0\n",
      "Mean Reward 30.015037594\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  133\n",
      "Reward:  28.0\n",
      "Mean Reward 30.0\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  134\n",
      "Reward:  26.0\n",
      "Mean Reward 29.9703703704\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  135\n",
      "Reward:  39.0\n",
      "Mean Reward 30.0367647059\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  136\n",
      "Reward:  16.0\n",
      "Mean Reward 29.9343065693\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  137\n",
      "Reward:  76.0\n",
      "Mean Reward 30.268115942\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  138\n",
      "Reward:  19.0\n",
      "Mean Reward 30.1870503597\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  139\n",
      "Reward:  64.0\n",
      "Mean Reward 30.4285714286\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  140\n",
      "Reward:  21.0\n",
      "Mean Reward 30.3617021277\n",
      "Max reward so far:  136.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  141\n",
      "Reward:  72.0\n",
      "Mean Reward 30.6549295775\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  142\n",
      "Reward:  36.0\n",
      "Mean Reward 30.6923076923\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  143\n",
      "Reward:  28.0\n",
      "Mean Reward 30.6736111111\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  144\n",
      "Reward:  27.0\n",
      "Mean Reward 30.6482758621\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  145\n",
      "Reward:  93.0\n",
      "Mean Reward 31.0753424658\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  146\n",
      "Reward:  20.0\n",
      "Mean Reward 31.0\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  147\n",
      "Reward:  80.0\n",
      "Mean Reward 31.3310810811\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  148\n",
      "Reward:  105.0\n",
      "Mean Reward 31.8255033557\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  149\n",
      "Reward:  16.0\n",
      "Mean Reward 31.72\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  150\n",
      "Reward:  93.0\n",
      "Mean Reward 32.1258278146\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  151\n",
      "Reward:  71.0\n",
      "Mean Reward 32.3815789474\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  152\n",
      "Reward:  25.0\n",
      "Mean Reward 32.3333333333\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  153\n",
      "Reward:  73.0\n",
      "Mean Reward 32.5974025974\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  154\n",
      "Reward:  51.0\n",
      "Mean Reward 32.7161290323\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  155\n",
      "Reward:  43.0\n",
      "Mean Reward 32.7820512821\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  156\n",
      "Reward:  31.0\n",
      "Mean Reward 32.7707006369\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  157\n",
      "Reward:  95.0\n",
      "Mean Reward 33.164556962\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  158\n",
      "Reward:  34.0\n",
      "Mean Reward 33.1698113208\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  159\n",
      "Reward:  71.0\n",
      "Mean Reward 33.40625\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  160\n",
      "Reward:  68.0\n",
      "Mean Reward 33.6211180124\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  161\n",
      "Reward:  35.0\n",
      "Mean Reward 33.6296296296\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  162\n",
      "Reward:  74.0\n",
      "Mean Reward 33.8773006135\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  163\n",
      "Reward:  24.0\n",
      "Mean Reward 33.8170731707\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  164\n",
      "Reward:  95.0\n",
      "Mean Reward 34.1878787879\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  165\n",
      "Reward:  41.0\n",
      "Mean Reward 34.2289156627\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  166\n",
      "Reward:  56.0\n",
      "Mean Reward 34.3592814371\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  167\n",
      "Reward:  73.0\n",
      "Mean Reward 34.5892857143\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  168\n",
      "Reward:  52.0\n",
      "Mean Reward 34.6923076923\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  169\n",
      "Reward:  15.0\n",
      "Mean Reward 34.5764705882\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  170\n",
      "Reward:  31.0\n",
      "Mean Reward 34.5555555556\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  171\n",
      "Reward:  12.0\n",
      "Mean Reward 34.4244186047\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  172\n",
      "Reward:  41.0\n",
      "Mean Reward 34.4624277457\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  173\n",
      "Reward:  13.0\n",
      "Mean Reward 34.3390804598\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  174\n",
      "Reward:  25.0\n",
      "Mean Reward 34.2857142857\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  175\n",
      "Reward:  135.0\n",
      "Mean Reward 34.8579545455\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  176\n",
      "Reward:  18.0\n",
      "Mean Reward 34.7627118644\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  177\n",
      "Reward:  50.0\n",
      "Mean Reward 34.8483146067\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  178\n",
      "Reward:  22.0\n",
      "Mean Reward 34.7765363128\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  179\n",
      "Reward:  25.0\n",
      "Mean Reward 34.7222222222\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  180\n",
      "Reward:  43.0\n",
      "Mean Reward 34.7679558011\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  181\n",
      "Reward:  34.0\n",
      "Mean Reward 34.7637362637\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  182\n",
      "Reward:  26.0\n",
      "Mean Reward 34.7158469945\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  183\n",
      "Reward:  59.0\n",
      "Mean Reward 34.847826087\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  184\n",
      "Reward:  23.0\n",
      "Mean Reward 34.7837837838\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  185\n",
      "Reward:  35.0\n",
      "Mean Reward 34.7849462366\n",
      "Max reward so far:  136.0\n",
      "==========================================\n",
      "Episode:  186\n",
      "Reward:  145.0\n",
      "Mean Reward 35.3743315508\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  187\n",
      "Reward:  64.0\n",
      "Mean Reward 35.5265957447\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  188\n",
      "Reward:  84.0\n",
      "Mean Reward 35.7830687831\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  189\n",
      "Reward:  34.0\n",
      "Mean Reward 35.7736842105\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  190\n",
      "Reward:  105.0\n",
      "Mean Reward 36.1361256545\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  191\n",
      "Reward:  29.0\n",
      "Mean Reward 36.0989583333\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  192\n",
      "Reward:  59.0\n",
      "Mean Reward 36.2176165803\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  193\n",
      "Reward:  29.0\n",
      "Mean Reward 36.1804123711\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  194\n",
      "Reward:  30.0\n",
      "Mean Reward 36.1487179487\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  195\n",
      "Reward:  94.0\n",
      "Mean Reward 36.443877551\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  196\n",
      "Reward:  55.0\n",
      "Mean Reward 36.538071066\n",
      "Max reward so far:  145.0\n",
      "==========================================\n",
      "Episode:  197\n",
      "Reward:  221.0\n",
      "Mean Reward 37.4696969697\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  198\n",
      "Reward:  69.0\n",
      "Mean Reward 37.6281407035\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  199\n",
      "Reward:  19.0\n",
      "Mean Reward 37.535\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  200\n",
      "Reward:  45.0\n",
      "Mean Reward 37.5721393035\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  201\n",
      "Reward:  69.0\n",
      "Mean Reward 37.7277227723\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  202\n",
      "Reward:  188.0\n",
      "Mean Reward 38.4679802956\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  203\n",
      "Reward:  17.0\n",
      "Mean Reward 38.362745098\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  204\n",
      "Reward:  18.0\n",
      "Mean Reward 38.2634146341\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  205\n",
      "Reward:  145.0\n",
      "Mean Reward 38.7815533981\n",
      "Max reward so far:  221.0\n",
      "==========================================\n",
      "Episode:  206\n",
      "Reward:  239.0\n",
      "Mean Reward 39.7487922705\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  207\n",
      "Reward:  56.0\n",
      "Mean Reward 39.8269230769\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  208\n",
      "Reward:  39.0\n",
      "Mean Reward 39.8229665072\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  209\n",
      "Reward:  66.0\n",
      "Mean Reward 39.9476190476\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  210\n",
      "Reward:  80.0\n",
      "Mean Reward 40.1374407583\n",
      "Max reward so far:  239.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  211\n",
      "Reward:  47.0\n",
      "Mean Reward 40.1698113208\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  212\n",
      "Reward:  17.0\n",
      "Mean Reward 40.0610328638\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  213\n",
      "Reward:  152.0\n",
      "Mean Reward 40.5841121495\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  214\n",
      "Reward:  121.0\n",
      "Mean Reward 40.9581395349\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  215\n",
      "Reward:  104.0\n",
      "Mean Reward 41.25\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  216\n",
      "Reward:  86.0\n",
      "Mean Reward 41.4562211982\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  217\n",
      "Reward:  76.0\n",
      "Mean Reward 41.6146788991\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  218\n",
      "Reward:  137.0\n",
      "Mean Reward 42.0502283105\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  219\n",
      "Reward:  21.0\n",
      "Mean Reward 41.9545454545\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  220\n",
      "Reward:  195.0\n",
      "Mean Reward 42.6470588235\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  221\n",
      "Reward:  150.0\n",
      "Mean Reward 43.1306306306\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  222\n",
      "Reward:  183.0\n",
      "Mean Reward 43.7578475336\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  223\n",
      "Reward:  14.0\n",
      "Mean Reward 43.625\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  224\n",
      "Reward:  46.0\n",
      "Mean Reward 43.6355555556\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  225\n",
      "Reward:  29.0\n",
      "Mean Reward 43.5707964602\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  226\n",
      "Reward:  33.0\n",
      "Mean Reward 43.5242290749\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  227\n",
      "Reward:  194.0\n",
      "Mean Reward 44.1842105263\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  228\n",
      "Reward:  115.0\n",
      "Mean Reward 44.4934497817\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  229\n",
      "Reward:  39.0\n",
      "Mean Reward 44.4695652174\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  230\n",
      "Reward:  156.0\n",
      "Mean Reward 44.9523809524\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  231\n",
      "Reward:  144.0\n",
      "Mean Reward 45.3793103448\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  232\n",
      "Reward:  134.0\n",
      "Mean Reward 45.7596566524\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  233\n",
      "Reward:  188.0\n",
      "Mean Reward 46.3675213675\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  234\n",
      "Reward:  35.0\n",
      "Mean Reward 46.3191489362\n",
      "Max reward so far:  239.0\n",
      "==========================================\n",
      "Episode:  235\n",
      "Reward:  273.0\n",
      "Mean Reward 47.2796610169\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  236\n",
      "Reward:  57.0\n",
      "Mean Reward 47.3206751055\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  237\n",
      "Reward:  80.0\n",
      "Mean Reward 47.4579831933\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  238\n",
      "Reward:  128.0\n",
      "Mean Reward 47.7949790795\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  239\n",
      "Reward:  206.0\n",
      "Mean Reward 48.4541666667\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  240\n",
      "Reward:  106.0\n",
      "Mean Reward 48.6929460581\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  241\n",
      "Reward:  50.0\n",
      "Mean Reward 48.6983471074\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  242\n",
      "Reward:  202.0\n",
      "Mean Reward 49.329218107\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  243\n",
      "Reward:  165.0\n",
      "Mean Reward 49.8032786885\n",
      "Max reward so far:  273.0\n",
      "==========================================\n",
      "Episode:  244\n",
      "Reward:  373.0\n",
      "Mean Reward 51.1224489796\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  245\n",
      "Reward:  125.0\n",
      "Mean Reward 51.4227642276\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  246\n",
      "Reward:  169.0\n",
      "Mean Reward 51.8987854251\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  247\n",
      "Reward:  151.0\n",
      "Mean Reward 52.2983870968\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  248\n",
      "Reward:  222.0\n",
      "Mean Reward 52.9799196787\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  249\n",
      "Reward:  165.0\n",
      "Mean Reward 53.428\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  250\n",
      "Reward:  165.0\n",
      "Mean Reward 53.8725099602\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  251\n",
      "Reward:  203.0\n",
      "Mean Reward 54.4642857143\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  252\n",
      "Reward:  153.0\n",
      "Mean Reward 54.8537549407\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  253\n",
      "Reward:  221.0\n",
      "Mean Reward 55.5078740157\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  254\n",
      "Reward:  154.0\n",
      "Mean Reward 55.8941176471\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  255\n",
      "Reward:  191.0\n",
      "Mean Reward 56.421875\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  256\n",
      "Reward:  255.0\n",
      "Mean Reward 57.1945525292\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  257\n",
      "Reward:  204.0\n",
      "Mean Reward 57.7635658915\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  258\n",
      "Reward:  214.0\n",
      "Mean Reward 58.3667953668\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  259\n",
      "Reward:  235.0\n",
      "Mean Reward 59.0461538462\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  260\n",
      "Reward:  164.0\n",
      "Mean Reward 59.4482758621\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  261\n",
      "Reward:  160.0\n",
      "Mean Reward 59.8320610687\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  262\n",
      "Reward:  253.0\n",
      "Mean Reward 60.566539924\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  263\n",
      "Reward:  70.0\n",
      "Mean Reward 60.6022727273\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  264\n",
      "Reward:  18.0\n",
      "Mean Reward 60.441509434\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  265\n",
      "Reward:  47.0\n",
      "Mean Reward 60.3909774436\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  266\n",
      "Reward:  153.0\n",
      "Mean Reward 60.7378277154\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  267\n",
      "Reward:  200.0\n",
      "Mean Reward 61.2574626866\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  268\n",
      "Reward:  149.0\n",
      "Mean Reward 61.5836431227\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  269\n",
      "Reward:  59.0\n",
      "Mean Reward 61.5740740741\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  270\n",
      "Reward:  150.0\n",
      "Mean Reward 61.9003690037\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  271\n",
      "Reward:  67.0\n",
      "Mean Reward 61.9191176471\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  272\n",
      "Reward:  171.0\n",
      "Mean Reward 62.3186813187\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  273\n",
      "Reward:  154.0\n",
      "Mean Reward 62.6532846715\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  274\n",
      "Reward:  126.0\n",
      "Mean Reward 62.8836363636\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  275\n",
      "Reward:  61.0\n",
      "Mean Reward 62.8768115942\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  276\n",
      "Reward:  226.0\n",
      "Mean Reward 63.4657039711\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  277\n",
      "Reward:  162.0\n",
      "Mean Reward 63.8201438849\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  278\n",
      "Reward:  141.0\n",
      "Mean Reward 64.0967741935\n",
      "Max reward so far:  373.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  279\n",
      "Reward:  234.0\n",
      "Mean Reward 64.7035714286\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  280\n",
      "Reward:  240.0\n",
      "Mean Reward 65.3274021352\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  281\n",
      "Reward:  172.0\n",
      "Mean Reward 65.7056737589\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  282\n",
      "Reward:  139.0\n",
      "Mean Reward 65.964664311\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  283\n",
      "Reward:  157.0\n",
      "Mean Reward 66.2852112676\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  284\n",
      "Reward:  195.0\n",
      "Mean Reward 66.7368421053\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  285\n",
      "Reward:  330.0\n",
      "Mean Reward 67.6573426573\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  286\n",
      "Reward:  202.0\n",
      "Mean Reward 68.1254355401\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  287\n",
      "Reward:  194.0\n",
      "Mean Reward 68.5625\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  288\n",
      "Reward:  281.0\n",
      "Mean Reward 69.2975778547\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  289\n",
      "Reward:  172.0\n",
      "Mean Reward 69.6517241379\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  290\n",
      "Reward:  321.0\n",
      "Mean Reward 70.5154639175\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  291\n",
      "Reward:  156.0\n",
      "Mean Reward 70.8082191781\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  292\n",
      "Reward:  197.0\n",
      "Mean Reward 71.2389078498\n",
      "Max reward so far:  373.0\n",
      "==========================================\n",
      "Episode:  293\n",
      "Reward:  454.0\n",
      "Mean Reward 72.5408163265\n",
      "Max reward so far:  454.0\n",
      "==========================================\n",
      "Episode:  294\n",
      "Reward:  302.0\n",
      "Mean Reward 73.3186440678\n",
      "Max reward so far:  454.0\n",
      "==========================================\n",
      "Episode:  295\n",
      "Reward:  377.0\n",
      "Mean Reward 74.3445945946\n",
      "Max reward so far:  454.0\n",
      "==========================================\n",
      "Episode:  296\n",
      "Reward:  274.0\n",
      "Mean Reward 75.0168350168\n",
      "Max reward so far:  454.0\n",
      "==========================================\n",
      "Episode:  297\n",
      "Reward:  623.0\n",
      "Mean Reward 76.855704698\n",
      "Max reward so far:  623.0\n",
      "==========================================\n",
      "Episode:  298\n",
      "Reward:  716.0\n",
      "Mean Reward 78.9933110368\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  299\n",
      "Reward:  219.0\n",
      "Mean Reward 79.46\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  300\n",
      "Reward:  384.0\n",
      "Mean Reward 80.4717607973\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  301\n",
      "Reward:  210.0\n",
      "Mean Reward 80.9006622517\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  302\n",
      "Reward:  159.0\n",
      "Mean Reward 81.1584158416\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  303\n",
      "Reward:  312.0\n",
      "Mean Reward 81.9177631579\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  304\n",
      "Reward:  521.0\n",
      "Mean Reward 83.3573770492\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  305\n",
      "Reward:  678.0\n",
      "Mean Reward 85.3006535948\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  306\n",
      "Reward:  426.0\n",
      "Mean Reward 86.4104234528\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  307\n",
      "Reward:  173.0\n",
      "Mean Reward 86.6915584416\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  308\n",
      "Reward:  239.0\n",
      "Mean Reward 87.1844660194\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  309\n",
      "Reward:  490.0\n",
      "Mean Reward 88.4838709677\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  310\n",
      "Reward:  257.0\n",
      "Mean Reward 89.0257234727\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  311\n",
      "Reward:  61.0\n",
      "Mean Reward 88.9358974359\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  312\n",
      "Reward:  287.0\n",
      "Mean Reward 89.5686900958\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  313\n",
      "Reward:  291.0\n",
      "Mean Reward 90.2101910828\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  314\n",
      "Reward:  511.0\n",
      "Mean Reward 91.546031746\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  315\n",
      "Reward:  284.0\n",
      "Mean Reward 92.1550632911\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  316\n",
      "Reward:  654.0\n",
      "Mean Reward 93.927444795\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  317\n",
      "Reward:  247.0\n",
      "Mean Reward 94.4088050314\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  318\n",
      "Reward:  565.0\n",
      "Mean Reward 95.8840125392\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  319\n",
      "Reward:  240.0\n",
      "Mean Reward 96.334375\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  320\n",
      "Reward:  401.0\n",
      "Mean Reward 97.2834890966\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  321\n",
      "Reward:  616.0\n",
      "Mean Reward 98.8944099379\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  322\n",
      "Reward:  374.0\n",
      "Mean Reward 99.746130031\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  323\n",
      "Reward:  574.0\n",
      "Mean Reward 101.209876543\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  324\n",
      "Reward:  542.0\n",
      "Mean Reward 102.566153846\n",
      "Max reward so far:  716.0\n",
      "==========================================\n",
      "Episode:  325\n",
      "Reward:  1443.0\n",
      "Mean Reward 106.67791411\n",
      "Max reward so far:  1443.0\n",
      "==========================================\n",
      "Episode:  326\n",
      "Reward:  438.0\n",
      "Mean Reward 107.691131498\n",
      "Max reward so far:  1443.0\n",
      "==========================================\n",
      "Episode:  327\n",
      "Reward:  2382.0\n",
      "Mean Reward 114.625\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  328\n",
      "Reward:  664.0\n",
      "Mean Reward 116.294832827\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  329\n",
      "Reward:  1433.0\n",
      "Mean Reward 120.284848485\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  330\n",
      "Reward:  569.0\n",
      "Mean Reward 121.640483384\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  331\n",
      "Reward:  722.0\n",
      "Mean Reward 123.448795181\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  332\n",
      "Reward:  737.0\n",
      "Mean Reward 125.291291291\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  333\n",
      "Reward:  577.0\n",
      "Mean Reward 126.643712575\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  334\n",
      "Reward:  1303.0\n",
      "Mean Reward 130.155223881\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  335\n",
      "Reward:  290.0\n",
      "Mean Reward 130.630952381\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  336\n",
      "Reward:  579.0\n",
      "Mean Reward 131.961424332\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  337\n",
      "Reward:  578.0\n",
      "Mean Reward 133.281065089\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  338\n",
      "Reward:  556.0\n",
      "Mean Reward 134.528023599\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  339\n",
      "Reward:  362.0\n",
      "Mean Reward 135.197058824\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  340\n",
      "Reward:  346.0\n",
      "Mean Reward 135.815249267\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  341\n",
      "Reward:  236.0\n",
      "Mean Reward 136.108187135\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  342\n",
      "Reward:  328.0\n",
      "Mean Reward 136.667638484\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  343\n",
      "Reward:  246.0\n",
      "Mean Reward 136.985465116\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  344\n",
      "Reward:  190.0\n",
      "Mean Reward 137.139130435\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  345\n",
      "Reward:  179.0\n",
      "Mean Reward 137.260115607\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  346\n",
      "Reward:  259.0\n",
      "Mean Reward 137.610951009\n",
      "Max reward so far:  2382.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  347\n",
      "Reward:  211.0\n",
      "Mean Reward 137.82183908\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  348\n",
      "Reward:  266.0\n",
      "Mean Reward 138.189111748\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  349\n",
      "Reward:  254.0\n",
      "Mean Reward 138.52\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  350\n",
      "Reward:  216.0\n",
      "Mean Reward 138.740740741\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  351\n",
      "Reward:  335.0\n",
      "Mean Reward 139.298295455\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  352\n",
      "Reward:  257.0\n",
      "Mean Reward 139.631728045\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  353\n",
      "Reward:  198.0\n",
      "Mean Reward 139.796610169\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  354\n",
      "Reward:  220.0\n",
      "Mean Reward 140.022535211\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  355\n",
      "Reward:  146.0\n",
      "Mean Reward 140.039325843\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  356\n",
      "Reward:  199.0\n",
      "Mean Reward 140.204481793\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  357\n",
      "Reward:  198.0\n",
      "Mean Reward 140.365921788\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  358\n",
      "Reward:  201.0\n",
      "Mean Reward 140.534818942\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  359\n",
      "Reward:  185.0\n",
      "Mean Reward 140.658333333\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  360\n",
      "Reward:  194.0\n",
      "Mean Reward 140.806094183\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  361\n",
      "Reward:  201.0\n",
      "Mean Reward 140.972375691\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  362\n",
      "Reward:  170.0\n",
      "Mean Reward 141.052341598\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  363\n",
      "Reward:  204.0\n",
      "Mean Reward 141.225274725\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  364\n",
      "Reward:  180.0\n",
      "Mean Reward 141.331506849\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  365\n",
      "Reward:  162.0\n",
      "Mean Reward 141.387978142\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  366\n",
      "Reward:  166.0\n",
      "Mean Reward 141.455040872\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  367\n",
      "Reward:  138.0\n",
      "Mean Reward 141.445652174\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  368\n",
      "Reward:  157.0\n",
      "Mean Reward 141.487804878\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  369\n",
      "Reward:  128.0\n",
      "Mean Reward 141.451351351\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  370\n",
      "Reward:  139.0\n",
      "Mean Reward 141.444743935\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  371\n",
      "Reward:  152.0\n",
      "Mean Reward 141.47311828\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  372\n",
      "Reward:  125.0\n",
      "Mean Reward 141.428954424\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  373\n",
      "Reward:  112.0\n",
      "Mean Reward 141.35026738\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  374\n",
      "Reward:  176.0\n",
      "Mean Reward 141.442666667\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  375\n",
      "Reward:  161.0\n",
      "Mean Reward 141.494680851\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  376\n",
      "Reward:  184.0\n",
      "Mean Reward 141.607427056\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  377\n",
      "Reward:  157.0\n",
      "Mean Reward 141.648148148\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  378\n",
      "Reward:  140.0\n",
      "Mean Reward 141.643799472\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  379\n",
      "Reward:  162.0\n",
      "Mean Reward 141.697368421\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  380\n",
      "Reward:  156.0\n",
      "Mean Reward 141.734908136\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  381\n",
      "Reward:  179.0\n",
      "Mean Reward 141.832460733\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  382\n",
      "Reward:  220.0\n",
      "Mean Reward 142.036553525\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  383\n",
      "Reward:  168.0\n",
      "Mean Reward 142.104166667\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  384\n",
      "Reward:  172.0\n",
      "Mean Reward 142.181818182\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  385\n",
      "Reward:  103.0\n",
      "Mean Reward 142.080310881\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  386\n",
      "Reward:  181.0\n",
      "Mean Reward 142.180878553\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  387\n",
      "Reward:  132.0\n",
      "Mean Reward 142.154639175\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  388\n",
      "Reward:  163.0\n",
      "Mean Reward 142.208226221\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  389\n",
      "Reward:  134.0\n",
      "Mean Reward 142.187179487\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  390\n",
      "Reward:  111.0\n",
      "Mean Reward 142.10741688\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  391\n",
      "Reward:  122.0\n",
      "Mean Reward 142.056122449\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  392\n",
      "Reward:  129.0\n",
      "Mean Reward 142.022900763\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  393\n",
      "Reward:  50.0\n",
      "Mean Reward 141.789340102\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  394\n",
      "Reward:  125.0\n",
      "Mean Reward 141.746835443\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  395\n",
      "Reward:  103.0\n",
      "Mean Reward 141.648989899\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  396\n",
      "Reward:  24.0\n",
      "Mean Reward 141.352644836\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  397\n",
      "Reward:  115.0\n",
      "Mean Reward 141.286432161\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  398\n",
      "Reward:  119.0\n",
      "Mean Reward 141.230576441\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  399\n",
      "Reward:  37.0\n",
      "Mean Reward 140.97\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  400\n",
      "Reward:  134.0\n",
      "Mean Reward 140.952618454\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  401\n",
      "Reward:  108.0\n",
      "Mean Reward 140.870646766\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  402\n",
      "Reward:  53.0\n",
      "Mean Reward 140.652605459\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  403\n",
      "Reward:  98.0\n",
      "Mean Reward 140.547029703\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  404\n",
      "Reward:  134.0\n",
      "Mean Reward 140.530864198\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  405\n",
      "Reward:  91.0\n",
      "Mean Reward 140.408866995\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  406\n",
      "Reward:  126.0\n",
      "Mean Reward 140.373464373\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  407\n",
      "Reward:  133.0\n",
      "Mean Reward 140.355392157\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  408\n",
      "Reward:  124.0\n",
      "Mean Reward 140.315403423\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  409\n",
      "Reward:  139.0\n",
      "Mean Reward 140.312195122\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  410\n",
      "Reward:  135.0\n",
      "Mean Reward 140.299270073\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  411\n",
      "Reward:  135.0\n",
      "Mean Reward 140.286407767\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  412\n",
      "Reward:  151.0\n",
      "Mean Reward 140.312348668\n",
      "Max reward so far:  2382.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  413\n",
      "Reward:  158.0\n",
      "Mean Reward 140.355072464\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  414\n",
      "Reward:  175.0\n",
      "Mean Reward 140.438554217\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  415\n",
      "Reward:  164.0\n",
      "Mean Reward 140.495192308\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  416\n",
      "Reward:  195.0\n",
      "Mean Reward 140.625899281\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  417\n",
      "Reward:  150.0\n",
      "Mean Reward 140.648325359\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  418\n",
      "Reward:  145.0\n",
      "Mean Reward 140.658711217\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  419\n",
      "Reward:  185.0\n",
      "Mean Reward 140.764285714\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  420\n",
      "Reward:  203.0\n",
      "Mean Reward 140.912114014\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  421\n",
      "Reward:  151.0\n",
      "Mean Reward 140.936018957\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  422\n",
      "Reward:  145.0\n",
      "Mean Reward 140.945626478\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  423\n",
      "Reward:  157.0\n",
      "Mean Reward 140.983490566\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  424\n",
      "Reward:  183.0\n",
      "Mean Reward 141.082352941\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  425\n",
      "Reward:  146.0\n",
      "Mean Reward 141.093896714\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  426\n",
      "Reward:  133.0\n",
      "Mean Reward 141.074941452\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  427\n",
      "Reward:  132.0\n",
      "Mean Reward 141.053738318\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  428\n",
      "Reward:  142.0\n",
      "Mean Reward 141.055944056\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  429\n",
      "Reward:  140.0\n",
      "Mean Reward 141.053488372\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  430\n",
      "Reward:  132.0\n",
      "Mean Reward 141.032482599\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  431\n",
      "Reward:  194.0\n",
      "Mean Reward 141.155092593\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  432\n",
      "Reward:  155.0\n",
      "Mean Reward 141.187066975\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  433\n",
      "Reward:  133.0\n",
      "Mean Reward 141.168202765\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  434\n",
      "Reward:  167.0\n",
      "Mean Reward 141.227586207\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  435\n",
      "Reward:  149.0\n",
      "Mean Reward 141.245412844\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  436\n",
      "Reward:  138.0\n",
      "Mean Reward 141.23798627\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  437\n",
      "Reward:  150.0\n",
      "Mean Reward 141.257990868\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  438\n",
      "Reward:  132.0\n",
      "Mean Reward 141.23690205\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  439\n",
      "Reward:  180.0\n",
      "Mean Reward 141.325\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  440\n",
      "Reward:  129.0\n",
      "Mean Reward 141.297052154\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  441\n",
      "Reward:  153.0\n",
      "Mean Reward 141.323529412\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  442\n",
      "Reward:  189.0\n",
      "Mean Reward 141.431151242\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  443\n",
      "Reward:  138.0\n",
      "Mean Reward 141.423423423\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  444\n",
      "Reward:  169.0\n",
      "Mean Reward 141.485393258\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  445\n",
      "Reward:  143.0\n",
      "Mean Reward 141.488789238\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  446\n",
      "Reward:  21.0\n",
      "Mean Reward 141.219239374\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  447\n",
      "Reward:  167.0\n",
      "Mean Reward 141.276785714\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  448\n",
      "Reward:  150.0\n",
      "Mean Reward 141.296213808\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  449\n",
      "Reward:  128.0\n",
      "Mean Reward 141.266666667\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  450\n",
      "Reward:  147.0\n",
      "Mean Reward 141.279379157\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  451\n",
      "Reward:  133.0\n",
      "Mean Reward 141.261061947\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  452\n",
      "Reward:  142.0\n",
      "Mean Reward 141.262693157\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  453\n",
      "Reward:  137.0\n",
      "Mean Reward 141.253303965\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  454\n",
      "Reward:  110.0\n",
      "Mean Reward 141.184615385\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  455\n",
      "Reward:  114.0\n",
      "Mean Reward 141.125\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  456\n",
      "Reward:  121.0\n",
      "Mean Reward 141.080962801\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  457\n",
      "Reward:  116.0\n",
      "Mean Reward 141.026200873\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  458\n",
      "Reward:  98.0\n",
      "Mean Reward 140.932461874\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  459\n",
      "Reward:  92.0\n",
      "Mean Reward 140.826086957\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  460\n",
      "Reward:  116.0\n",
      "Mean Reward 140.772234273\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  461\n",
      "Reward:  122.0\n",
      "Mean Reward 140.731601732\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  462\n",
      "Reward:  141.0\n",
      "Mean Reward 140.732181425\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  463\n",
      "Reward:  145.0\n",
      "Mean Reward 140.74137931\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  464\n",
      "Reward:  107.0\n",
      "Mean Reward 140.668817204\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  465\n",
      "Reward:  123.0\n",
      "Mean Reward 140.630901288\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  466\n",
      "Reward:  178.0\n",
      "Mean Reward 140.710920771\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  467\n",
      "Reward:  150.0\n",
      "Mean Reward 140.730769231\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  468\n",
      "Reward:  138.0\n",
      "Mean Reward 140.724946695\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  469\n",
      "Reward:  199.0\n",
      "Mean Reward 140.84893617\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  470\n",
      "Reward:  204.0\n",
      "Mean Reward 140.983014862\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  471\n",
      "Reward:  208.0\n",
      "Mean Reward 141.125\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  472\n",
      "Reward:  366.0\n",
      "Mean Reward 141.600422833\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  473\n",
      "Reward:  228.0\n",
      "Mean Reward 141.782700422\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  474\n",
      "Reward:  235.0\n",
      "Mean Reward 141.978947368\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  475\n",
      "Reward:  203.0\n",
      "Mean Reward 142.107142857\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  476\n",
      "Reward:  340.0\n",
      "Mean Reward 142.522012579\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  477\n",
      "Reward:  196.0\n",
      "Mean Reward 142.633891213\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  478\n",
      "Reward:  232.0\n",
      "Mean Reward 142.82045929\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  479\n",
      "Reward:  327.0\n",
      "Mean Reward 143.204166667\n",
      "Max reward so far:  2382.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  480\n",
      "Reward:  249.0\n",
      "Mean Reward 143.424116424\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  481\n",
      "Reward:  272.0\n",
      "Mean Reward 143.690871369\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  482\n",
      "Reward:  299.0\n",
      "Mean Reward 144.01242236\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  483\n",
      "Reward:  496.0\n",
      "Mean Reward 144.739669421\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  484\n",
      "Reward:  238.0\n",
      "Mean Reward 144.931958763\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  485\n",
      "Reward:  454.0\n",
      "Mean Reward 145.567901235\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  486\n",
      "Reward:  321.0\n",
      "Mean Reward 145.928131417\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  487\n",
      "Reward:  337.0\n",
      "Mean Reward 146.319672131\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  488\n",
      "Reward:  378.0\n",
      "Mean Reward 146.793456033\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  489\n",
      "Reward:  242.0\n",
      "Mean Reward 146.987755102\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  490\n",
      "Reward:  363.0\n",
      "Mean Reward 147.427698574\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  491\n",
      "Reward:  247.0\n",
      "Mean Reward 147.630081301\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  492\n",
      "Reward:  286.0\n",
      "Mean Reward 147.910750507\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  493\n",
      "Reward:  301.0\n",
      "Mean Reward 148.220647773\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  494\n",
      "Reward:  382.0\n",
      "Mean Reward 148.692929293\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  495\n",
      "Reward:  375.0\n",
      "Mean Reward 149.149193548\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  496\n",
      "Reward:  411.0\n",
      "Mean Reward 149.676056338\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  497\n",
      "Reward:  372.0\n",
      "Mean Reward 150.12248996\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  498\n",
      "Reward:  298.0\n",
      "Mean Reward 150.418837675\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  499\n",
      "Reward:  323.0\n",
      "Mean Reward 150.764\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  500\n",
      "Reward:  218.0\n",
      "Mean Reward 150.898203593\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  501\n",
      "Reward:  317.0\n",
      "Mean Reward 151.229083665\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  502\n",
      "Reward:  294.0\n",
      "Mean Reward 151.512922465\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  503\n",
      "Reward:  306.0\n",
      "Mean Reward 151.819444444\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  504\n",
      "Reward:  321.0\n",
      "Mean Reward 152.154455446\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  505\n",
      "Reward:  561.0\n",
      "Mean Reward 152.962450593\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  506\n",
      "Reward:  368.0\n",
      "Mean Reward 153.386587771\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  507\n",
      "Reward:  297.0\n",
      "Mean Reward 153.669291339\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  508\n",
      "Reward:  402.0\n",
      "Mean Reward 154.157170923\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  509\n",
      "Reward:  445.0\n",
      "Mean Reward 154.72745098\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  510\n",
      "Reward:  391.0\n",
      "Mean Reward 155.189823875\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  511\n",
      "Reward:  391.0\n",
      "Mean Reward 155.650390625\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  512\n",
      "Reward:  372.0\n",
      "Mean Reward 156.072124756\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  513\n",
      "Reward:  267.0\n",
      "Mean Reward 156.287937743\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  514\n",
      "Reward:  317.0\n",
      "Mean Reward 156.6\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  515\n",
      "Reward:  405.0\n",
      "Mean Reward 157.081395349\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  516\n",
      "Reward:  372.0\n",
      "Mean Reward 157.497098646\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  517\n",
      "Reward:  289.0\n",
      "Mean Reward 157.750965251\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  518\n",
      "Reward:  262.0\n",
      "Mean Reward 157.951830443\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  519\n",
      "Reward:  363.0\n",
      "Mean Reward 158.346153846\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  520\n",
      "Reward:  362.0\n",
      "Mean Reward 158.737044146\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  521\n",
      "Reward:  258.0\n",
      "Mean Reward 158.927203065\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  522\n",
      "Reward:  364.0\n",
      "Mean Reward 159.319311663\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  523\n",
      "Reward:  289.0\n",
      "Mean Reward 159.566793893\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  524\n",
      "Reward:  264.0\n",
      "Mean Reward 159.765714286\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  525\n",
      "Reward:  269.0\n",
      "Mean Reward 159.97338403\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  526\n",
      "Reward:  247.0\n",
      "Mean Reward 160.138519924\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  527\n",
      "Reward:  255.0\n",
      "Mean Reward 160.318181818\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  528\n",
      "Reward:  417.0\n",
      "Mean Reward 160.803402647\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  529\n",
      "Reward:  336.0\n",
      "Mean Reward 161.133962264\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  530\n",
      "Reward:  292.0\n",
      "Mean Reward 161.380414313\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  531\n",
      "Reward:  264.0\n",
      "Mean Reward 161.573308271\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  532\n",
      "Reward:  269.0\n",
      "Mean Reward 161.774859287\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  533\n",
      "Reward:  210.0\n",
      "Mean Reward 161.865168539\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  534\n",
      "Reward:  187.0\n",
      "Mean Reward 161.912149533\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  535\n",
      "Reward:  210.0\n",
      "Mean Reward 162.001865672\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  536\n",
      "Reward:  203.0\n",
      "Mean Reward 162.078212291\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  537\n",
      "Reward:  198.0\n",
      "Mean Reward 162.144981413\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  538\n",
      "Reward:  216.0\n",
      "Mean Reward 162.244897959\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  539\n",
      "Reward:  176.0\n",
      "Mean Reward 162.27037037\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  540\n",
      "Reward:  161.0\n",
      "Mean Reward 162.268022181\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  541\n",
      "Reward:  182.0\n",
      "Mean Reward 162.304428044\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  542\n",
      "Reward:  133.0\n",
      "Mean Reward 162.250460405\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  543\n",
      "Reward:  136.0\n",
      "Mean Reward 162.202205882\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  544\n",
      "Reward:  132.0\n",
      "Mean Reward 162.146788991\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  545\n",
      "Reward:  143.0\n",
      "Mean Reward 162.111721612\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  546\n",
      "Reward:  147.0\n",
      "Mean Reward 162.084095064\n",
      "Max reward so far:  2382.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  547\n",
      "Reward:  150.0\n",
      "Mean Reward 162.062043796\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  548\n",
      "Reward:  139.0\n",
      "Mean Reward 162.02003643\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  549\n",
      "Reward:  140.0\n",
      "Mean Reward 161.98\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  550\n",
      "Reward:  140.0\n",
      "Mean Reward 161.940108893\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  551\n",
      "Reward:  139.0\n",
      "Mean Reward 161.898550725\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  552\n",
      "Reward:  136.0\n",
      "Mean Reward 161.851717902\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  553\n",
      "Reward:  126.0\n",
      "Mean Reward 161.78700361\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  554\n",
      "Reward:  137.0\n",
      "Mean Reward 161.742342342\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  555\n",
      "Reward:  126.0\n",
      "Mean Reward 161.678057554\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  556\n",
      "Reward:  127.0\n",
      "Mean Reward 161.615798923\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  557\n",
      "Reward:  128.0\n",
      "Mean Reward 161.555555556\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  558\n",
      "Reward:  113.0\n",
      "Mean Reward 161.468694097\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  559\n",
      "Reward:  112.0\n",
      "Mean Reward 161.380357143\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  560\n",
      "Reward:  124.0\n",
      "Mean Reward 161.31372549\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  561\n",
      "Reward:  127.0\n",
      "Mean Reward 161.252669039\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  562\n",
      "Reward:  131.0\n",
      "Mean Reward 161.198934281\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  563\n",
      "Reward:  109.0\n",
      "Mean Reward 161.106382979\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  564\n",
      "Reward:  102.0\n",
      "Mean Reward 161.001769912\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  565\n",
      "Reward:  116.0\n",
      "Mean Reward 160.922261484\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  566\n",
      "Reward:  104.0\n",
      "Mean Reward 160.821869489\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  567\n",
      "Reward:  127.0\n",
      "Mean Reward 160.762323944\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  568\n",
      "Reward:  114.0\n",
      "Mean Reward 160.680140598\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  569\n",
      "Reward:  141.0\n",
      "Mean Reward 160.645614035\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  570\n",
      "Reward:  128.0\n",
      "Mean Reward 160.588441331\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  571\n",
      "Reward:  120.0\n",
      "Mean Reward 160.517482517\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  572\n",
      "Reward:  110.0\n",
      "Mean Reward 160.429319372\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  573\n",
      "Reward:  133.0\n",
      "Mean Reward 160.381533101\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  574\n",
      "Reward:  125.0\n",
      "Mean Reward 160.32\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  575\n",
      "Reward:  142.0\n",
      "Mean Reward 160.288194444\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  576\n",
      "Reward:  109.0\n",
      "Mean Reward 160.199306759\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  577\n",
      "Reward:  158.0\n",
      "Mean Reward 160.19550173\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  578\n",
      "Reward:  139.0\n",
      "Mean Reward 160.158894646\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  579\n",
      "Reward:  175.0\n",
      "Mean Reward 160.184482759\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  580\n",
      "Reward:  141.0\n",
      "Mean Reward 160.151462995\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  581\n",
      "Reward:  155.0\n",
      "Mean Reward 160.142611684\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  582\n",
      "Reward:  185.0\n",
      "Mean Reward 160.185248714\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  583\n",
      "Reward:  162.0\n",
      "Mean Reward 160.188356164\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  584\n",
      "Reward:  145.0\n",
      "Mean Reward 160.162393162\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  585\n",
      "Reward:  207.0\n",
      "Mean Reward 160.242320819\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  586\n",
      "Reward:  187.0\n",
      "Mean Reward 160.2879046\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  587\n",
      "Reward:  185.0\n",
      "Mean Reward 160.329931973\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  588\n",
      "Reward:  178.0\n",
      "Mean Reward 160.359932088\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  589\n",
      "Reward:  217.0\n",
      "Mean Reward 160.455932203\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  590\n",
      "Reward:  177.0\n",
      "Mean Reward 160.48392555\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  591\n",
      "Reward:  225.0\n",
      "Mean Reward 160.592905405\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  592\n",
      "Reward:  195.0\n",
      "Mean Reward 160.650927487\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  593\n",
      "Reward:  216.0\n",
      "Mean Reward 160.744107744\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  594\n",
      "Reward:  192.0\n",
      "Mean Reward 160.796638655\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  595\n",
      "Reward:  234.0\n",
      "Mean Reward 160.919463087\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  596\n",
      "Reward:  213.0\n",
      "Mean Reward 161.006700168\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  597\n",
      "Reward:  233.0\n",
      "Mean Reward 161.127090301\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  598\n",
      "Reward:  230.0\n",
      "Mean Reward 161.242070117\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  599\n",
      "Reward:  273.0\n",
      "Mean Reward 161.428333333\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  600\n",
      "Reward:  332.0\n",
      "Mean Reward 161.712146423\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  601\n",
      "Reward:  253.0\n",
      "Mean Reward 161.863787375\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  602\n",
      "Reward:  291.0\n",
      "Mean Reward 162.077943615\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  603\n",
      "Reward:  273.0\n",
      "Mean Reward 162.261589404\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  604\n",
      "Reward:  341.0\n",
      "Mean Reward 162.557024793\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  605\n",
      "Reward:  376.0\n",
      "Mean Reward 162.909240924\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  606\n",
      "Reward:  306.0\n",
      "Mean Reward 163.144975288\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  607\n",
      "Reward:  440.0\n",
      "Mean Reward 163.600328947\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  608\n",
      "Reward:  496.0\n",
      "Mean Reward 164.146141215\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  609\n",
      "Reward:  362.0\n",
      "Mean Reward 164.470491803\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  610\n",
      "Reward:  367.0\n",
      "Mean Reward 164.801963993\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  611\n",
      "Reward:  354.0\n",
      "Mean Reward 165.111111111\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  612\n",
      "Reward:  341.0\n",
      "Mean Reward 165.398042414\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  613\n",
      "Reward:  348.0\n",
      "Mean Reward 165.695439739\n",
      "Max reward so far:  2382.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  614\n",
      "Reward:  304.0\n",
      "Mean Reward 165.920325203\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  615\n",
      "Reward:  489.0\n",
      "Mean Reward 166.444805195\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  616\n",
      "Reward:  395.0\n",
      "Mean Reward 166.815235008\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  617\n",
      "Reward:  421.0\n",
      "Mean Reward 167.226537217\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  618\n",
      "Reward:  348.0\n",
      "Mean Reward 167.518578352\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  619\n",
      "Reward:  375.0\n",
      "Mean Reward 167.853225806\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  620\n",
      "Reward:  618.0\n",
      "Mean Reward 168.578099839\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  621\n",
      "Reward:  407.0\n",
      "Mean Reward 168.961414791\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  622\n",
      "Reward:  400.0\n",
      "Mean Reward 169.332263242\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  623\n",
      "Reward:  463.0\n",
      "Mean Reward 169.802884615\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  624\n",
      "Reward:  495.0\n",
      "Mean Reward 170.3232\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  625\n",
      "Reward:  424.0\n",
      "Mean Reward 170.728434505\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  626\n",
      "Reward:  629.0\n",
      "Mean Reward 171.459330144\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  627\n",
      "Reward:  495.0\n",
      "Mean Reward 171.974522293\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  628\n",
      "Reward:  794.0\n",
      "Mean Reward 172.963434022\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  629\n",
      "Reward:  1109.0\n",
      "Mean Reward 174.449206349\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  630\n",
      "Reward:  638.0\n",
      "Mean Reward 175.183835182\n",
      "Max reward so far:  2382.0\n",
      "==========================================\n",
      "Episode:  631\n",
      "Reward:  3887.0\n",
      "Mean Reward 181.056962025\n",
      "Max reward so far:  3887.0\n",
      "==========================================\n",
      "Episode:  632\n",
      "Reward:  4275.0\n",
      "Mean Reward 187.524486572\n",
      "Max reward so far:  4275.0\n",
      "==========================================\n",
      "Episode:  633\n",
      "Reward:  3131.0\n",
      "Mean Reward 192.167192429\n",
      "Max reward so far:  4275.0\n",
      "==========================================\n",
      "Episode:  634\n",
      "Reward:  856.0\n",
      "Mean Reward 193.212598425\n",
      "Max reward so far:  4275.0\n",
      "==========================================\n",
      "Episode:  635\n",
      "Reward:  4983.0\n",
      "Mean Reward 200.743710692\n",
      "Max reward so far:  4983.0\n",
      "==========================================\n",
      "Episode:  636\n",
      "Reward:  1635.0\n",
      "Mean Reward 202.995290424\n",
      "Max reward so far:  4983.0\n",
      "==========================================\n",
      "Episode:  637\n",
      "Reward:  1762.0\n",
      "Mean Reward 205.438871473\n",
      "Max reward so far:  4983.0\n",
      "==========================================\n",
      "Episode:  638\n",
      "Reward:  4370.0\n",
      "Mean Reward 211.956181534\n",
      "Max reward so far:  4983.0\n",
      "==========================================\n",
      "Episode:  639\n",
      "Reward:  1957.0\n",
      "Mean Reward 214.6828125\n",
      "Max reward so far:  4983.0\n",
      "==========================================\n",
      "Episode:  640\n",
      "Reward:  3719.0\n",
      "Mean Reward 220.149765991\n",
      "Max reward so far:  4983.0\n",
      "==========================================\n",
      "Episode:  641\n",
      "Reward:  5925.0\n",
      "Mean Reward 229.035825545\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  642\n",
      "Reward:  1992.0\n",
      "Mean Reward 231.777604977\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  643\n",
      "Reward:  898.0\n",
      "Mean Reward 232.812111801\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  644\n",
      "Reward:  1641.0\n",
      "Mean Reward 234.995348837\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  645\n",
      "Reward:  2424.0\n",
      "Mean Reward 238.383900929\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  646\n",
      "Reward:  5560.0\n",
      "Mean Reward 246.608964451\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  647\n",
      "Reward:  3249.0\n",
      "Mean Reward 251.242283951\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  648\n",
      "Reward:  1141.0\n",
      "Mean Reward 252.613251156\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  649\n",
      "Reward:  1862.0\n",
      "Mean Reward 255.089230769\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  650\n",
      "Reward:  3554.0\n",
      "Mean Reward 260.156682028\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  651\n",
      "Reward:  1815.0\n",
      "Mean Reward 262.541411043\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  652\n",
      "Reward:  2848.0\n",
      "Mean Reward 266.500765697\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  653\n",
      "Reward:  3379.0\n",
      "Mean Reward 271.259938838\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  654\n",
      "Reward:  5255.0\n",
      "Mean Reward 278.86870229\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  655\n",
      "Reward:  1444.0\n",
      "Mean Reward 280.644817073\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  656\n",
      "Reward:  3264.0\n",
      "Mean Reward 285.185692542\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  657\n",
      "Reward:  1530.0\n",
      "Mean Reward 287.077507599\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  658\n",
      "Reward:  1765.0\n",
      "Mean Reward 289.320182094\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  659\n",
      "Reward:  4871.0\n",
      "Mean Reward 296.262121212\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  660\n",
      "Reward:  1164.0\n",
      "Mean Reward 297.574886536\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  661\n",
      "Reward:  3609.0\n",
      "Mean Reward 302.577039275\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  662\n",
      "Reward:  3351.0\n",
      "Mean Reward 307.174962293\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  663\n",
      "Reward:  3991.0\n",
      "Mean Reward 312.722891566\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  664\n",
      "Reward:  2080.0\n",
      "Mean Reward 315.380451128\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  665\n",
      "Reward:  3960.0\n",
      "Mean Reward 320.852852853\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  666\n",
      "Reward:  5212.0\n",
      "Mean Reward 328.185907046\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  667\n",
      "Reward:  1408.0\n",
      "Mean Reward 329.80239521\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  668\n",
      "Reward:  3689.0\n",
      "Mean Reward 334.823617339\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  669\n",
      "Reward:  2374.0\n",
      "Mean Reward 337.867164179\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  670\n",
      "Reward:  980.0\n",
      "Mean Reward 338.82414307\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  671\n",
      "Reward:  3725.0\n",
      "Mean Reward 343.863095238\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  672\n",
      "Reward:  2068.0\n",
      "Mean Reward 346.424962853\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  673\n",
      "Reward:  1578.0\n",
      "Mean Reward 348.252225519\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  674\n",
      "Reward:  4532.0\n",
      "Mean Reward 354.45037037\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  675\n",
      "Reward:  2048.0\n",
      "Mean Reward 356.955621302\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  676\n",
      "Reward:  1521.0\n",
      "Mean Reward 358.675036928\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  677\n",
      "Reward:  1411.0\n",
      "Mean Reward 360.227138643\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  678\n",
      "Reward:  1473.0\n",
      "Mean Reward 361.865979381\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  679\n",
      "Reward:  857.0\n",
      "Mean Reward 362.594117647\n",
      "Max reward so far:  5925.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Episode:  680\n",
      "Reward:  1072.0\n",
      "Mean Reward 363.635829662\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  681\n",
      "Reward:  762.0\n",
      "Mean Reward 364.219941349\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  682\n",
      "Reward:  629.0\n",
      "Mean Reward 364.60761347\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  683\n",
      "Reward:  684.0\n",
      "Mean Reward 365.074561404\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  684\n",
      "Reward:  720.0\n",
      "Mean Reward 365.59270073\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  685\n",
      "Reward:  545.0\n",
      "Mean Reward 365.854227405\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  686\n",
      "Reward:  608.0\n",
      "Mean Reward 366.206695779\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  687\n",
      "Reward:  433.0\n",
      "Mean Reward 366.30377907\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  688\n",
      "Reward:  552.0\n",
      "Mean Reward 366.57329463\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  689\n",
      "Reward:  489.0\n",
      "Mean Reward 366.750724638\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  690\n",
      "Reward:  465.0\n",
      "Mean Reward 366.892908828\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  691\n",
      "Reward:  559.0\n",
      "Mean Reward 367.170520231\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  692\n",
      "Reward:  386.0\n",
      "Mean Reward 367.197691198\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  693\n",
      "Reward:  354.0\n",
      "Mean Reward 367.178674352\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  694\n",
      "Reward:  416.0\n",
      "Mean Reward 367.248920863\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  695\n",
      "Reward:  425.0\n",
      "Mean Reward 367.331896552\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  696\n",
      "Reward:  293.0\n",
      "Mean Reward 367.225251076\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  697\n",
      "Reward:  407.0\n",
      "Mean Reward 367.282234957\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  698\n",
      "Reward:  357.0\n",
      "Mean Reward 367.267525036\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  699\n",
      "Reward:  341.0\n",
      "Mean Reward 367.23\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  700\n",
      "Reward:  430.0\n",
      "Mean Reward 367.319543509\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  701\n",
      "Reward:  462.0\n",
      "Mean Reward 367.454415954\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  702\n",
      "Reward:  425.0\n",
      "Mean Reward 367.536273115\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  703\n",
      "Reward:  393.0\n",
      "Mean Reward 367.572443182\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  704\n",
      "Reward:  654.0\n",
      "Mean Reward 367.978723404\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  705\n",
      "Reward:  485.0\n",
      "Mean Reward 368.144475921\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  706\n",
      "Reward:  666.0\n",
      "Mean Reward 368.565770863\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  707\n",
      "Reward:  964.0\n",
      "Mean Reward 369.406779661\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  708\n",
      "Reward:  1215.0\n",
      "Mean Reward 370.599435825\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  709\n",
      "Reward:  1184.0\n",
      "Mean Reward 371.745070423\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  710\n",
      "Reward:  1452.0\n",
      "Mean Reward 373.264416315\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  711\n",
      "Reward:  4416.0\n",
      "Mean Reward 378.94241573\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  712\n",
      "Reward:  4410.0\n",
      "Mean Reward 384.596072931\n",
      "Max reward so far:  5925.0\n",
      "==========================================\n",
      "Episode:  713\n",
      "Reward:  6152.0\n",
      "Mean Reward 392.673669468\n",
      "Max reward so far:  6152.0\n",
      "==========================================\n",
      "Episode:  714\n",
      "Reward:  64950.0\n",
      "Mean Reward 482.963636364\n",
      "Max reward so far:  64950.0\n",
      "==========================================\n",
      "Episode:  715\n",
      "Reward:  12649.0\n",
      "Mean Reward 499.955307263\n",
      "Max reward so far:  64950.0\n",
      "==========================================\n",
      "Episode:  716\n",
      "Reward:  227780.0\n",
      "Mean Reward 816.942817294\n",
      "Max reward so far:  227780.0\n",
      "==========================================\n",
      "Episode:  717\n",
      "Reward:  146049.0\n",
      "Mean Reward 1019.21587744\n",
      "Max reward so far:  227780.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-80e4f3bd8032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# Choose action a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0maction_probability_distribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_distribution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gameplai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gameplai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gameplai\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \"\"\"\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allRewards = []\n",
    "total_rewards = 0\n",
    "maximumRewardRecorded = 0\n",
    "episode = 0\n",
    "episode_states, episode_actions, episode_rewards = [],[],[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for episode in range(max_episodes):\n",
    "        \n",
    "        episode_rewards_sum = 0\n",
    "\n",
    "        # Launch the game\n",
    "        state = env.reset()\n",
    "        \n",
    "        env.render()\n",
    "           \n",
    "        while True:\n",
    "            \n",
    "            # Choose action a, remember WE'RE NOT IN A DETERMINISTIC ENVIRONMENT, WE'RE OUTPUT PROBABILITIES.\n",
    "            action_probability_distribution = sess.run(action_distribution, feed_dict={input_: state.reshape([1,4])})\n",
    "            \n",
    "            action = np.random.choice(range(action_probability_distribution.shape[1]), p=action_probability_distribution.ravel())  # select action w.r.t the actions prob\n",
    "\n",
    "            # Perform a\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Store s, a, r\n",
    "            episode_states.append(state)\n",
    "                        \n",
    "            # For actions because we output only one (the index) we need 2 (1 is for the action taken)\n",
    "            # We need [0., 1.] (if we take right) not just the index\n",
    "            action_ = np.zeros(action_size)\n",
    "            action_[action] = 1\n",
    "            \n",
    "            episode_actions.append(action_)\n",
    "            \n",
    "            episode_rewards.append(reward)\n",
    "            if done:\n",
    "                # Calculate sum reward\n",
    "                episode_rewards_sum = np.sum(episode_rewards)\n",
    "                \n",
    "                allRewards.append(episode_rewards_sum)\n",
    "                \n",
    "                total_rewards = np.sum(allRewards)\n",
    "                \n",
    "                # Mean reward\n",
    "                mean_reward = np.divide(total_rewards, episode+1)\n",
    "                \n",
    "                \n",
    "                maximumRewardRecorded = np.amax(allRewards)\n",
    "                \n",
    "                print(\"==========================================\")\n",
    "                print(\"Episode: \", episode)\n",
    "                print(\"Reward: \", episode_rewards_sum)\n",
    "                print(\"Mean Reward\", mean_reward)\n",
    "                print(\"Max reward so far: \", maximumRewardRecorded)\n",
    "                \n",
    "                # Calculate discounted reward\n",
    "                discounted_episode_rewards = discount_and_normalize_rewards(episode_rewards)\n",
    "                                \n",
    "                # Feedforward, gradient and backpropagation\n",
    "                loss_, _ = sess.run([loss, train_opt], feed_dict={input_: np.vstack(np.array(episode_states)),\n",
    "                                                                 actions: np.vstack(np.array(episode_actions)),\n",
    "                                                                 discounted_episode_rewards_: discounted_episode_rewards \n",
    "                                                                })\n",
    "                \n",
    " \n",
    "                                                                 \n",
    "                # Write TF Summaries\n",
    "                summary = sess.run(write_op, feed_dict={input_: np.vstack(np.array(episode_states)),\n",
    "                                                                 actions: np.vstack(np.array(episode_actions)),\n",
    "                                                                 discounted_episode_rewards_: discounted_episode_rewards,\n",
    "                                                                    mean_reward_: mean_reward\n",
    "                                                                })\n",
    "                \n",
    "               \n",
    "                writer.add_summary(summary, episode)\n",
    "                writer.flush()\n",
    "                \n",
    "                # Reset the transition stores\n",
    "                episode_states, episode_actions, episode_rewards = [],[],[]\n",
    "                \n",
    "                break\n",
    "            \n",
    "            state = new_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
